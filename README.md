This project focuses on developing an accurate and robust image classification model for identifying animal species using Convolutional Neural Networks (CNN). Leveraging the power of transfer learning, the MobileNet architecture, pre-trained on the extensive ImageNet dataset, served as the foundation for the model. The dataset was meticulously prepared by resizing images to 224x224 pixels, normalizing pixel values, and applying data augmentation techniques, including random rotations, shifts, shears, zooms, and horizontal flips to the training set. This augmentation process aimed to increase the model's ability to generalize and prevent overfitting. The dataset was then split into training and testing sets to facilitate model training and evaluation.
The model architecture incorporated the MobileNet base model as a feature extractor, followed by a global average pooling layer to reduce dimensionality. A dense layer with 128 units and ReLU activation was added for further feature extraction, and a dropout layer was included to mitigate overfitting. Finally, a dense layer with SoftMax activation enabled classification, outputting probabilities for each animal category. The model was compiled using the Adam optimizer, categorical cross-entropy loss function, and accuracy metric. To address potential class imbalance, class weights were calculated and applied during training.
The training process involved monitoring the model's learning progress through visualization of training and validation accuracy curves. Callbacks, such as ReduceLROnPlateau and EarlyStopping, were employed to dynamically adjust the learning rate and prevent overfitting by stopping training early if performance plateaued. Evaluation on the testing set demonstrated high accuracy, signifying the model's effectiveness in classifying animal images. A confusion matrix was generated and visualized as a heatmap to provide detailed insights into the model's predictions and identify potential areas for improvement.
